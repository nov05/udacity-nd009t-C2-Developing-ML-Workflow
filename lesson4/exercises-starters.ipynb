{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* changed by nov05 on 2024-11-24  \n",
    "* [Exercise](https://www.evernote.com/shard/s139/u/0/sh/d22b9fe5-9992-4dd0-9402-c623cdbc90b4/rJcBRGAXxAQfdkl3kqgZ1N2VIKFVDSOLDimPDJFMhwHEQmyRu0AHwQTqxw), [solution](https://www.evernote.com/shard/s139/u/0/sh/00654bdd-0c00-4525-a0e4-beeeccb17e18/UdvEWior2s6PYMczVqGFVPf1PM_g35bFRrPiVlm79SfmnVhyPY_BJQPsiw)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "This is the notebook containing the exercises for Feature Store, Model Monitor, and Clarify. Tested for these exercises was performed using __2 vCPU + 4 GiB notebook instance with Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized) kernel__.\n",
    "\n",
    "## Staging\n",
    "\n",
    "We'll begin by initializing some variables. These are often assumed to be present in code samples you'll find in the AWS documenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role ARN: arn:aws:iam::807711953667:role/service-role/AmazonSageMaker-ExecutionRole-20241121T213663\n"
     ]
    }
   ],
   "source": [
    "import sagemaker # type: ignore\n",
    "from sagemaker import get_execution_role # type: ignore\n",
    "from sagemaker.session import Session # type: ignore\n",
    "\n",
    "role_arn = get_execution_role()  ## get role ARN\n",
    "if 'AmazonSageMaker-ExecutionRole' not in role_arn:\n",
    "    role_arn = \"arn:aws:iam::807711953667:role/service-role/AmazonSageMaker-ExecutionRole-20241121T213663\"\n",
    "print(\"Role ARN:\", role_arn) ## If local, Role ARN: arn:aws:iam::807711953667:role/voclabs\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "# bucket = session.default_bucket()\n",
    "bucket = \"sagemaker-studio-807711953667-mmx0am1bt28\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üëâ Feature Store**  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Store is a special database to give ML systems a consistent data flow across training and inference workloads. It can ingest data in batches (for training) as well as serve input features to models with very low latency for real-time prediction.\n",
    "\n",
    "For this exercise we'll work with a wine quality dataset: https://archive.ics.uci.edu/ml/datasets/wine+quality/\n",
    "\n",
    "```\n",
    "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
      "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
      "       'proanthocyanins', 'color_intensity', 'hue',\n",
      "       'od280/od315_of_diluted_wines', 'proline'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # type: ignore\n",
    "from sklearn import datasets # type: ignore\n",
    "import time\n",
    "# import uuid\n",
    "\n",
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we leave the column names as-is, Feature Store won't be able to handle the `/` in `od280/od315_of_diluted_wines` (`/` is a delimiter Feature Store uses to manage how features are organized.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280_od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>EventTime</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.51</td>\n",
       "      <td>24.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.72</td>\n",
       "      <td>630.0</td>\n",
       "      <td>1.732473e+09</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.22</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2.51</td>\n",
       "      <td>13.2</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.53</td>\n",
       "      <td>760.0</td>\n",
       "      <td>1.732473e+09</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>11.61</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.70</td>\n",
       "      <td>20.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.26</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1.732473e+09</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "82     12.08        1.13  2.51               24.0       78.0           2.00   \n",
       "39     14.22        3.99  2.51               13.2      128.0           3.00   \n",
       "109    11.61        1.35  2.70               20.0       94.0           2.74   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "82         1.58                  0.40             1.40             2.20  1.31   \n",
       "39         3.04                  0.20             2.08             5.10  0.89   \n",
       "109        2.92                  0.29             2.49             2.65  0.96   \n",
       "\n",
       "     od280_od315_of_diluted_wines  proline     EventTime   ID  \n",
       "82                           2.72    630.0  1.732473e+09   82  \n",
       "39                           3.53    760.0  1.732473e+09   39  \n",
       "109                          3.26    680.0  1.732473e+09  109  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)\n",
    "## Add columns for feature group\n",
    "df[\"EventTime\"] = time.time()\n",
    "df[\"ID\"] = range(len(df))\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data, we can create a feature group. Remember to attach event time and ID columns - Feature Store needs them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='alcohol', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='malic_acid', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='alcalinity_of_ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='magnesium', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='total_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='flavanoids', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='nonflavanoid_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='proanthocyanins', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='color_intensity', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='hue', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='od280_od315_of_diluted_wines', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='proline', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='EventTime', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='ID', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>, collection_type=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup # type: ignore\n",
    " \n",
    "# TODO: Create feature group\n",
    "feature_group_name = \"wine-features\"\n",
    "feature_group = FeatureGroup(\n",
    "    name=feature_group_name, \n",
    "    sagemaker_session=session\n",
    ")\n",
    "# TODO: Load Feature definitions\n",
    "feature_group.load_feature_definitions(data_frame=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature group is not created until we call the `create` method, let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:807711953667:feature-group/wine-features',\n",
       " 'ResponseMetadata': {'RequestId': '9adc9df7-1db7-4c01-85ea-063dc7aa4f9d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '9adc9df7-1db7-4c01-85ea-063dc7aa4f9d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '90',\n",
       "   'date': 'Sun, 24 Nov 2024 18:28:03 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the feature store:\n",
    "feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/features\",\n",
    "    record_identifier_name='ID',\n",
    "    event_time_feature_name=\"EventTime\",\n",
    "    role_arn=role_arn,\n",
    "    enable_online_store=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üü¢‚ö†Ô∏è Issue explained: I got the following response when creating from a local notebook. However, the creation failed. Go to `SageMaker Studio > Data > Feature Store`. Click on the feature group. Click on the ‚ÄúDetails‚Äù tab. It seems the assumed role doesn‚Äôt have certain permissions. While creating from a SageMaker notebook, it succeeded.      \n",
    "```\n",
    "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:807711953667:feature-group/wine-features',\n",
    " 'ResponseMetadata': {'RequestId': 'd49e3486-e1cb-414e-86fe-0f56d5fbf5fa',\n",
    "  'HTTPStatusCode': 200,\n",
    "  'HTTPHeaders': {'x-amzn-requestid': 'd49e3486-e1cb-414e-86fe-0f56d5fbf5fa',\n",
    "   'content-type': 'application/x-amz-json-1.1',\n",
    "   'content-length': '90',\n",
    "   'date': 'Sun, 24 Nov 2024 17:56:18 GMT'},\n",
    "  'RetryAttempts': 0}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "feature_group = FeatureGroup(name=feature_group_name)\n",
    "feature_group_status = feature_group.describe()['FeatureGroupStatus']\n",
    "print(feature_group_status, type(feature_group_status))  ## CreateFailed <class 'str'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, ingest some data into your feature group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "if feature_group_status=='Created':\n",
    "    feature_group.ingest(data_frame=df, \n",
    "                        max_workers=5, \n",
    "                        wait=True)\n",
    "else:\n",
    "    print('‚ö†Ô∏è The feature group is not created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You've demonstrated your understanding of creating feature groups and ingesting data into them using Feature Store. Next up we'll cover Model Monitor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üëâ Model Monitor**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll create a monitoring schedule for a deployed model. We're going to provide code to help you deploy a model and get started, so that you can focus on Model Monitor for this exercise. __Remember to clean up your model before you end a work session__. We'll provide some code at the end to help you clean up your model. We'll begin by reloading our data from the previous exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = datasets.load_wine()\n",
    "# df = pd.DataFrame(data['data'])\n",
    "# df.columns = data['feature_names']\n",
    "# df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html  \n",
    "\n",
    "* Tips:   \n",
    "  * Ensuring the 'TARGET' Column is the First Column:  \n",
    "  *After the df.reset_index(inplace=True), the 'TARGET' column becomes the first column in the DataFrame. If the intention was to reorder the DataFrame columns, this sequence achieves that by popping the 'TARGET' column, making it the index, and then converting it back to a regular column (now at the front).*\n",
    "  * Removing the Column Before Resetting It:  \n",
    "  *df.pop('TARGET') removes 'TARGET' from the DataFrame, ensuring it is not duplicated when resetting the index (as reset_index() would otherwise add the index back as a new column).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_image = sagemaker.image_uris.retrieve(\"xgboost\", region, version='latest')\n",
    "s3_output_location = f\"s3://{bucket}/models/wine_model\"\n",
    "\n",
    "model=sagemaker.estimator.Estimator(\n",
    "    image_uri=algo_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "model.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    objective='reg:linear',\n",
    "    early_stopping_rounds=10,\n",
    "    num_round=200\n",
    ")\n",
    "model.fit({'train': s3_input_train, \n",
    "           'validation': s3_input_validation})\n",
    "## go to \"SageMaker - Training - Training jobs\". Make sure the job is completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your training job has finished, you can perform the first task in this exercise:   \n",
    "* Creating a data capture config. Configure your model to sample `34%` of inferences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sagemaker.model_monitor import DataCaptureConfig # type: ignore\n",
    "\n",
    "destination_s3_uri = f's3://{bucket}/data-capture'\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=34,\n",
    "    destination_s3_uri=destination_s3_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We'll use your config to deploy a model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")\n",
    "## go to \"SageMaker - Inference - Endpoints\" to check the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You should see an indicator like this when the deployment finishes:\n",
    "\n",
    "```\n",
    "-----------------!\n",
    "```\n",
    "We can test your deployment like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "inputs = test.copy()\n",
    "# Drop the target variable\n",
    "inputs = inputs.drop(columns=inputs.columns[0])\n",
    "x_pred = xgb_predictor.predict(inputs.sample(5).values).decode('utf-8')\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All systems go! To finish up the exercise, we're going to provide you with a `DefaultModelMonitor` and a suggested baseline. Combine the `xgb_predictor` and the provided `my_monitor` to configure the monitoring schedule for _hourly_ monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor # type: ignore\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat # type: ignore\n",
    "\n",
    "my_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "my_monitor.suggest_baseline(\n",
    "    baseline_dataset=f's3://{bucket}/data/train.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, provide the monitoring schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sagemaker.model_monitor import CronExpressionGenerator # type: ignore\n",
    "\n",
    "my_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name='wine-monitoring-schedule',\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    statistics=my_monitor.baseline_statistics(),\n",
    "    constraints=my_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You can check that your schedule was created by ~~selecting the `SageMaker components and registries` tab on the far left~~. In this exercise you configured Model Monitor to watch a simple model. Next, we'll monitor the same deployment for explainability.\n",
    "\n",
    "* Go to `Amazon SageMaker > Model dashboard > <your model> > Monitor schedule`   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. If you aren't going to follow up with the Clarify exercise within a few hours, use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()\n",
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üëâ Clarify**  \n",
    "\n",
    "For the last exercise we'll deploy an explainability monitor using [`Clarify`](https://aws.amazon.com/sagemaker/clarify/). We're going to use the model that you deployed in the last exercise, but if you cleaned up your deployments from the previous exercise, that's ok! You can rerun the deployment from the previous exercise up to the point where we deployed our model. It'll look like this:\n",
    "\n",
    "```python\n",
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")\n",
    "```\n",
    "\n",
    "Once your model is deployed, you can come back here. _REMINDER_: you need to clean up your deployment, don't leave it running overnight. We'll provide some code at the end to delete your deployment.\n",
    "\n",
    "*  Amazon SageMaker Examples:    \n",
    "  [Fairness and Explainability with `SageMaker Clarify`](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability.html)   \n",
    "\n",
    "## Prep\n",
    "\n",
    "We'll begin by reloading our data from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = datasets.load_wine()\n",
    "# df = pd.DataFrame(data['data'])\n",
    "# df.columns = data['feature_names']\n",
    "# df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"TARGET\"] = data['target']\n",
    "# df.set_index(df.pop('TARGET'), inplace=True)\n",
    "# df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delimiter = int(len(df)/2)\n",
    "# train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "# train.to_csv(\"train.csv\", header=False, index=False)\n",
    "# test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "# val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "# train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "# s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "# s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our data is staged and our model is deployed - let's monitor it for explainability. We need to define three config objects, the `SHAPConfig`, the `ModelConfig`, and the `ExplainabilityAnalysisConfig`. Below, we provide the `SHAPConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[train.mean().astype(int).to_list()[1:]],\n",
    "    num_samples=int(train.size),\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, fill in the blanks to define the `ModelConfig` and `ExplainabilityAnalysisConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=xgb_predictor.endpoint_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    content_type=\"text/csv\",\n",
    "    accept_type=\"text/csv\",\n",
    ")\n",
    "analysis_config = sagemaker.model_monitor.ExplainabilityAnalysisConfig(\n",
    "        explainability_config=shap_config,\n",
    "        model_config=model_config,\n",
    "        headers=train.columns.to_list()[1:],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply our config, we need to create the monitor object. This is what we'll apply all our config to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor = [\n",
    "    sagemaker.model_monitor.ModelExplainabilityMonitor(\n",
    "        role=role,\n",
    "        sagemaker_session=session,\n",
    "        max_runtime_in_seconds=1800,\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything's ready! Below, create a monitoring schedule using the configs we created. Set the schedule to run _daily_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "from sagemaker.model_monitor import CronExpressionGenerator  # type: ignore\n",
    "\n",
    "explainability_uri = f\"s3://{bucket}/model_explainability\"\n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=explainability_uri,\n",
    "    analysis_config=analysis_config,\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way to go! You can check that your schedule was created by selecting ~~the `SageMaker components and registries` tab on the far left~~. In this exercise you deployed a monitor for explainability to your SageMaker endpoint. This is the last exercise - you'll apply these learnings again in your Project at the end of the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. Use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: monitoring-schedule-2021-09-13-17-25-08-560\n",
      "\n",
      "Deleting Monitoring Schedule with name: wine-monitoring-schedule\n"
     ]
    }
   ],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()\n",
    "xgb_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
